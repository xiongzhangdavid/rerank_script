{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "def convert_to_datapipeline(image_set, im_url_col):\n",
    "    \"\"\"\n",
    "    prepare csv to use datapipluse's tagging model to extract category/gender label\n",
    "    \n",
    "    Args:\n",
    "        image_set  (dataframe): input query set or reference set dataframe \n",
    "        im_url_col (str): the image url column name\n",
    "\n",
    "    Returns:\n",
    "        image_set_dp (dataframe): the input for datapipeline\n",
    "    \"\"\"    \n",
    "    image_set_dp = pd.DataFrame(columns=['im_url', 'concepts', 'metadatas'])\n",
    "    image_set_dp['im_url'] = image_set[im_url_col]\n",
    "    image_set_dp['concepts'] = \"[{'model_name': None, 'version': None, 'labels': {'system': None, 'ground_truth_source': None, 'source_id': None}, 'objects': [{'tags': [{'tag_group': None, 'tag': None, 'full_tag': None, 'score': None}], 'box': None, 'score': None}], 'reference': []}, {'model_name': None, 'version': None, 'labels': {'system': None, 'ground_truth_source': None, 'source_id': None}, 'objects': [{'tags': [{'tag_group': None, 'full_tag': None, 'tag': None, 'score': None}], 'box': None, 'score': None}], 'reference': []}]\"\n",
    "    image_set_dp['metadatas'] = '{}'\n",
    "    image_set_dp.dropna(inplace=True)\n",
    "    return image_set_dp\n",
    "\n",
    "def split_dev_test(data_set, dev_frac, category):\n",
    "    \"\"\"\n",
    "    split data_set into dev/test set\n",
    "    Args:\n",
    "        data_set  (dataframe): the data set to be splitted\n",
    "        dev_frac  (float): the fraction of dev set\n",
    "        category  (string): split is done per category to maintain the distribution\n",
    "\n",
    "    Returns:\n",
    "        (dev_set, test_set)  (tuple): tuple of dev/test set dataframes\n",
    "    \"\"\"  \n",
    "    dev_set = data_set.groupby(category).apply(lambda x:x.sample(frac=dev_frac,random_state=0))\n",
    "    dev_set.reset_index(level=0, drop=True, inplace=True)\n",
    "    test_set = data_set.drop(dev_set.index)\n",
    "    return dev_set, test_set\n",
    "\n",
    "def extract_json_tag(element, is_gender=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        element  (dictionary): element in the json list\n",
    "        is_gender(bool): True -> extract gender label, False -> extract category label\n",
    "    Returns:\n",
    "        result (list): \n",
    "        if gender,  [im_name, gender, 4 scores in alphabetical order]\n",
    "        if category,[im_name, category, 20 scores in alphabetical order]\n",
    "    \"\"\"  \n",
    "    name = element['name'].split('/')[-1]\n",
    "    if name.endswith('.jpg'):\n",
    "        name = name[:-4]\n",
    "    scores = dict()\n",
    "    result = [name]\n",
    "    if is_gender:\n",
    "        #gender\n",
    "        for item in element['gender_detect']:\n",
    "            scores[item['tag']] = item['score']\n",
    "        category = element['gender_detect'][0]['tag']\n",
    "    else:\n",
    "        # category\n",
    "        for item in element['product_tagging_flat_backpack']:\n",
    "            if item['tag'].startswith('root||'):\n",
    "                scores[item['tag']] = item['score']\n",
    "        category = element['product_tagging_flat_backpack'][0]['tag']\n",
    "    keys = sorted(scores.keys())\n",
    "    result.append(category)\n",
    "    for key in keys:\n",
    "        result.append(scores[key])\n",
    "    return result\n",
    "\n",
    "def json_to_df(json_folder, is_gender=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        json_folder (string): path of json folder\n",
    "        is_gender   (bool): True -> extract gender label, False -> extract category label\n",
    "    Returns:\n",
    "        result_df (dataframe):\n",
    "        if gender, columns = ['im_name', 'gender', 4 tags in alphabetical order]\n",
    "        if category, columns =['im_name', 'category', 20 tags in alphabetical order]  \n",
    "    \"\"\"  \n",
    "    result_file_list = os.listdir(json_folder)\n",
    "    result_json = []\n",
    "    for result_file in result_file_list:\n",
    "        with open(os.path.join(json_folder, result_file), 'r') as f:\n",
    "            result_json += json.load(f)\n",
    "    result_data = list(map(lambda x:extract_json_tag(x, is_gender), result_json))\n",
    "    if is_gender:\n",
    "        cols = ['im_name', 'gender']\n",
    "        keys = list(map(lambda x:x['tag'], result_json[0]['gender_detect']))\n",
    "    else:\n",
    "        cols = ['im_name', 'category']\n",
    "        keys = []\n",
    "        for item in result_json[0]['product_tagging_flat_backpack']:\n",
    "            if item['tag'].startswith('root||'):\n",
    "                keys.append(item['tag'])\n",
    "    cols += sorted(keys)\n",
    "    result_df = pd.DataFrame(columns=cols, data=result_data)\n",
    "    return result_df\n",
    "\n",
    "def divide_to_img_list(img_folder, path_prefix, output_prefix, batch_size):\n",
    "    \"\"\"\n",
    "    split the images to img_list for mannually triggered multiprocessing when do local recognition\n",
    "    Args:\n",
    "        img_folder  (string): path img folder\n",
    "        path_prefix (string): path prefix in hydra2\n",
    "        output_prefix (string): output path + name prefix for img list\n",
    "        batch_size  (int): each img list contains batch_size imgs\n",
    "    Returns:\n",
    "        result_df (dataframe): columns = ['path']\n",
    "    \"\"\"  \n",
    "    image_names = os.listdir(img_folder)\n",
    "    df = pd.DataFrame(columns=['path'])\n",
    "    img_num = len(image_names)\n",
    "    shard = math.ceil(img_num / batch_size)\n",
    "    for i in range(shard):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min(img_num, start_idx + batch_size)\n",
    "        df = pd.DataFrame(columns=['path'], data=image_names[start_idx:end_idx])\n",
    "        df = df.apply(lambda row: os.path.join(path_prefix, row))\n",
    "        df.to_csv(output_prefix + str(i), index=False, header=False)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load query set, combining them, remove duplicate\n",
    "data_folder = os.path.join(os.getcwd(), 'data', 'gender')\n",
    "query_csvs = ['queryset_1347_gender_search_eval_v1.csv', 'queryset_1356_gender_search_eval_v3_ugc.csv']\n",
    "query = pd.DataFrame()\n",
    "for query_csv in query_csvs:\n",
    "    query_cur = pd.read_csv(os.path.join(data_folder, query_csv))\n",
    "    query = pd.concat([query, query_cur])\n",
    "#remove duplicate and reset index\n",
    "query.drop_duplicates(subset=['Query Set URL'],inplace=True)\n",
    "query.reset_index(inplace=True, drop=True)\n",
    "query['Image Id'] = query['Image Id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use download script to download images and do local recognition\n",
    "query_download = query[['Image Id', 'S3 URL', 'Category']]\n",
    "query_download.columns = ['im_name', 's3_url', 'category']\n",
    "query_download.to_csv(os.path.join(data_folder, 'gender_query_download.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the result from hydra2 result\n",
    "query_gender_predict = json_to_df(os.path.join(data_folder, 'query_gender_predict'), True)\n",
    "query_category_predict = json_to_df(os.path.join(data_folder, 'query_category_predict'), False)\n",
    "\n",
    "#concate predict result with query set\n",
    "query_w_predict = query.join(query_gender_predict.set_index('im_name'), on='Image Id', rsuffix='_predict')\n",
    "query_w_predict = query_w_predict.join(query_category_predict.set_index('im_name'), on='Image Id', rsuffix='_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split query set into dev/test set per category\n",
    "dev_query, test_query = split_dev_test(query_w_predict, 0.5, 'Category')\n",
    "\n",
    "#save dev/test query to data folder\n",
    "dev_query.to_csv(os.path.join(data_folder, 'dev_gender_query.csv'), index=False)\n",
    "test_query.to_csv(os.path.join(data_folder, 'test_gender_query.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load reference set and remove duplicates and reset index\n",
    "reference = pd.read_csv(os.path.join(data_folder, 'gender_ref_ops_export'))\n",
    "reference.drop_duplicates(subset=['im_url'],inplace=True)\n",
    "reference.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use download script to download images and do local recognition\n",
    "reference[['im_name', 's3_url', 'gender']].to_csv(os.path.join(data_folder, 'gender_ref_download.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after download images to hydra2 folder, split the images to img_list and do mannually triggered multiprocessing\n",
    "img_folder = '/home/xz/hydra2_home_mnt/data/gender_ref'\n",
    "path_prefix = '/home/zhangxiong/data/gender_ref'\n",
    "output_prefix = '/home/xz/hydra2_home_mnt/data/gender_img_list/gender_img_list_'\n",
    "batch_size = 30000\n",
    "\n",
    "divide_to_img_list(img_folder, path_prefix, output_prefix, batch_size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the result from hydra2 result\n",
    "ref_gender_predict = json_to_df(os.path.join(data_folder, 'ref_gender_predict'), True)\n",
    "ref_category_predict = json_to_df(os.path.join(data_folder, 'ref_category_predict'), False)\n",
    "\n",
    "#concate predict result with reference set and prepare csv for upload in dashboard\n",
    "reference_w_predict = reference.join(ref_gender_predict.set_index('im_name'), on='im_name', rsuffix='_predict')\n",
    "reference_w_predict = reference_w_predict.join(ref_category_predict.set_index('im_name'), on='im_name', rsuffix='_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save ref_w_predict\n",
    "reference_w_predict.to_csv(os.path.join(data_folder, 'ref_w_predict.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not upload scores to dashboard\n",
    "upload_cols = ['im_name', 's3_url', 'gender', 'category', 'source', 'gender_predict', 'category_predict']\n",
    "reference_upload = reference_w_predict[upload_cols]\n",
    "reference_upload.columns = reference_upload.columns.str.replace('s3_url','im_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split ref into dev/test set per gender\n",
    "dev_ref, test_ref = split_dev_test(reference_upload, 0.5, 'gender')\n",
    "\n",
    "#save dev/test query to data folder\n",
    "dev_ref.to_csv(os.path.join(data_folder, 'dev_gender_ref.csv'), index=False)\n",
    "test_ref.to_csv(os.path.join(data_folder, 'test_gender_ref.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
